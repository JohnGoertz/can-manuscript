{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.use(\"Cairo\")  # for saving SVGs that Affinity Designer can parse\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib as pl\n",
    "import dill\n",
    "\n",
    "import candas as can\n",
    "import gumbi as gmb\n",
    "from candas.learn import ParameterSet\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "code_pth = pl.Path.cwd()  # for running in Jupyter\n",
    "# code_pth = pl.Path(__file__)  # for running in terminal\n",
    "fig_pth = code_pth.parent\n",
    "data_pth = fig_pth / \"data\"\n",
    "graph_pth = fig_pth / \"graphics\"\n",
    "graph_pth.mkdir(exist_ok=True)\n",
    "\n",
    "gen_pth = fig_pth / \"generated\"\n",
    "gen_pth.mkdir(exist_ok=True)\n",
    "\n",
    "plt.style.use(str(can.style.breve))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use('style.mplstyle')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from utils import savefig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = ParameterSet.load(data_pth / \"ADVI_ParameterSets_220528.pkl\")\n",
    "\n",
    "\n",
    "def make_pair(row):\n",
    "    return \"-\".join(sorted([row.FPrimer, row.RPrimer]))\n",
    "\n",
    "\n",
    "data = (\n",
    "    ps.wide.query('Metric == \"mean\"')\n",
    "    .astype({\"BP\": float})\n",
    "    .assign(PrimerPair=lambda df: df.apply(make_pair, axis=1))\n",
    "    .groupby([\"Target\", \"PrimerPair\", \"Reporter\"])\n",
    "    .mean(numeric_only=True)\n",
    "    .drop_duplicates()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "selected = (\n",
    "    data.groupby([\"PrimerPair\", \"Reporter\"])\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"Observations\"})\n",
    "    .sort_values(\"Observations\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ").iloc[[0, 1, 4, 5, 6, 8, 38, 39, 42]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_full = gmb.DataSet(\n",
    "    data=data,\n",
    "    outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "    log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "    logit_vars=[\"GC\"],\n",
    ")\n",
    "stdzr = ds_full.stdzr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data = data[\n",
    "            ~((data.PrimerPair == 'FP004-RP004') & (data.Reporter == 'HEX'))\n",
    "        ]\n",
    "\n",
    "xval_data = data[\n",
    "            (data.PrimerPair == 'FP004-RP004') & (data.Reporter == 'HEX')\n",
    "        ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 10\n",
    "i = 3\n",
    "I = len(xval_data)\n",
    "    \n",
    "def get_train_vec(x, i):\n",
    "    \"\"\"\n",
    "    Get a training vector for the cross-validation\n",
    "    \"\"\"\n",
    "    is_train = np.array([1]*i + [0]*(I-i)).astype(bool)\n",
    "    np.random.RandomState(x*I+i).shuffle(is_train)\n",
    "    return is_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (6, 0), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6), (6, 7), (6, 8), (6, 9), (11, 0), (11, 1), (11, 2), (11, 3), (11, 4), (11, 5), (11, 6), (11, 7), (11, 8), (11, 9), (16, 0), (16, 1), (16, 2), (16, 3), (16, 4), (16, 5), (16, 6), (16, 7), (16, 8), (16, 9), (21, 0), (21, 1), (21, 2), (21, 3), (21, 4), (21, 5), (21, 6), (21, 7), (21, 8), (21, 9), (26, 0), (26, 1), (26, 2), (26, 3), (26, 4), (26, 5), (26, 6), (26, 7), (26, 8), (26, 9), (31, 0), (31, 1), (31, 2), (31, 3), (31, 4), (31, 5), (31, 6), (31, 7), (31, 8), (31, 9), (36, 0), (36, 1), (36, 2), (36, 3), (36, 4), (36, 5), (36, 6), (36, 7), (36, 8), (36, 9)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d811ecf184b4414ac07dd47f4c7e823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training set size:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145b24313be24eb38560284e431a471d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5ef750323b490f9210bd1c6679ac4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd11ce8c05b94d7d895641a76b80b027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840dde1c041346d1a5e70dac5f38400a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d939b107a52e456da7e116255a873e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a93dae3a0b24be18a5d3af1f64b69b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99cc376a7b94edfbf8530b7e8e196b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7807341bde0d4335b315e2ba5ebafe5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "rows = []\n",
    "\n",
    "x = 0\n",
    "\n",
    "if (gen_pth / \"Avg_model_xval.csv\").exists():\n",
    "    df = pd.read_csv(gen_pth / \"Avg_model_xval.csv\")\n",
    "    print(df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist())\n",
    "else:\n",
    "    df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"N_train\",\n",
    "            \"Iteration\",\n",
    "            \"Train_NLPD\",\n",
    "            \"Train_RMSE\",\n",
    "            \"Test_NLPD\",\n",
    "            \"Test_RMSE\",\n",
    "            \"TrainCode\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "for i in tqdm(range(1, I + 1, 5), desc=\"Training set size\", leave=True):\n",
    "    for j in tqdm(range(J), desc=\"Iteration\", leave=False):\n",
    "        \n",
    "        so_far = df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist()\n",
    "        if (i, j) in so_far:\n",
    "            continue\n",
    "        \n",
    "        is_train = get_train_vec(j, i)\n",
    "        train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "        k = 0\n",
    "        while train_code in df[\"TrainCode\"].values:\n",
    "            is_train = get_train_vec(j*1000+k*I, i)\n",
    "            train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "            k += 1\n",
    "\n",
    "        train_data = pd.concat([static_data, xval_data.iloc[is_train]])\n",
    "        test_data = xval_data.iloc[~is_train]\n",
    "\n",
    "        train_ds = gmb.DataSet(\n",
    "            data=train_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        test_ds = gmb.DataSet(\n",
    "            data=test_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            gp = gmb.GP(train_ds).fit(\n",
    "                continuous_dims=[\"BP\", \"GC\"], progressbar=False\n",
    "            )\n",
    "            test_preds = gp.predict_points(\n",
    "                gp.parray(**test_ds.wide[[\"BP\", \"GC\"]].to_dict(orient=\"list\"))\n",
    "            ).get(\"r\")\n",
    "            train_preds = gp.predict_points(\n",
    "                gp.parray(**xval_data.iloc[is_train][[\"BP\", \"GC\"]].to_dict(orient=\"list\"))\n",
    "            ).get(\"r\")\n",
    "        except LinAlgError:\n",
    "            continue\n",
    "\n",
    "        test_rmse = np.sqrt(np.mean((test_preds.μ - test_ds.wide[\"r\"]) ** 2))\n",
    "        train_rmse = np.sqrt(\n",
    "            np.mean((train_preds.μ - xval_data.iloc[is_train][\"r\"]) ** 2)\n",
    "        )\n",
    "\n",
    "        test_nlpd = -test_preds.dist.logpdf(test_ds.wide[\"r\"]).mean()\n",
    "        train_nlpd = -train_preds.dist.logpdf(xval_data.iloc[is_train][\"r\"]).mean()\n",
    "\n",
    "        test_nlpd, train_nlpd, test_rmse, train_rmse\n",
    "\n",
    "        row = {\n",
    "            \"N_train\": i,\n",
    "            \"Iteration\": j,\n",
    "            \"Train_NLPD\": train_nlpd,\n",
    "            \"Train_RMSE\": train_rmse,\n",
    "            \"Test_NLPD\": test_nlpd,\n",
    "            \"Test_RMSE\": test_rmse,\n",
    "            \"TrainCode\": train_code,\n",
    "        }\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([row])])\n",
    "        df.to_csv(gen_pth / \"Avg_model_xval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (6, 0), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6), (6, 7), (6, 8), (6, 9), (11, 0), (11, 1), (11, 2), (11, 3), (11, 4), (11, 5), (11, 6), (11, 7), (11, 8), (11, 9), (16, 0), (16, 1), (16, 2), (16, 3), (16, 4), (16, 5), (16, 6), (16, 7), (16, 8), (16, 9), (21, 0), (21, 1), (21, 2), (21, 3), (21, 4), (21, 5), (21, 6), (21, 7), (21, 8), (21, 9), (26, 0), (26, 1), (26, 2), (26, 3), (26, 4), (26, 5), (26, 6), (26, 7), (26, 8), (26, 9), (31, 0), (31, 1), (31, 2), (31, 3), (31, 4), (31, 5), (31, 6), (31, 7), (31, 8), (31, 9), (36, 0), (36, 1), (36, 2), (36, 3), (36, 4), (36, 5), (36, 6), (36, 7), (36, 8), (36, 9)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a9ff2e317c427ba729756e71a874f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training set size:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54acea3936ad4e9f8da558bacb8312ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3dd3f061324d0a912471d76e472364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b2bbe53d65466e9b654cb3ebe52b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e814e698ac84120a1800035c9cf1d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188e0319bad84f619f9e6160eb785ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac550458fca84c3bb447f57aa3dcf677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8bb67d3b0fd4e0aa82460072b85347c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b2b083a3824656b17407c7cd75ddff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "rows = []\n",
    "\n",
    "x = 0\n",
    "\n",
    "if (gen_pth / \"Ind_model_xval.csv\").exists():\n",
    "    df = pd.read_csv(gen_pth / \"Ind_model_xval.csv\")\n",
    "    print(df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist())\n",
    "else:\n",
    "    df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"N_train\",\n",
    "            \"Iteration\",\n",
    "            \"Train_NLPD\",\n",
    "            \"Train_RMSE\",\n",
    "            \"Test_NLPD\",\n",
    "            \"Test_RMSE\",\n",
    "            \"TrainCode\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "for i in tqdm(range(1, I + 1, 5), desc=\"Training set size\", leave=True):\n",
    "    for j in tqdm(range(J), desc=\"Iteration\", leave=False):\n",
    "        \n",
    "        so_far = df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist()\n",
    "        if (i, j) in so_far:\n",
    "            continue\n",
    "        \n",
    "        is_train = get_train_vec(j, i)\n",
    "        train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "        k = 0\n",
    "        while train_code in df[\"TrainCode\"].values:\n",
    "            is_train = get_train_vec(j*1000+k*I, i)\n",
    "            train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "            k += 1\n",
    "\n",
    "        train_data = xval_data.iloc[is_train]\n",
    "        test_data = xval_data.iloc[~is_train]\n",
    "\n",
    "        train_ds = gmb.DataSet(\n",
    "            data=train_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        test_ds = gmb.DataSet(\n",
    "            data=test_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            if train_ds.wide.shape[0] > 1:\n",
    "                gp = gmb.GP(train_ds).fit(\n",
    "                    continuous_dims=[\"BP\", \"GC\"], progressbar=False\n",
    "                )\n",
    "            else:\n",
    "                gp = gmb.GP(train_ds)\n",
    "                gp.specify_model(continuous_dims=[\"BP\", \"GC\"])\n",
    "                gp.filter_dims = {}\n",
    "                gp.continuous_dims = [\"BP\", \"GC\"]\n",
    "                gp.continuous_levels = gp._parse_levels(gp.continuous_dims, None)\n",
    "                gp.continuous_coords = gp._parse_coordinates(\n",
    "                    gp.continuous_dims, gp.continuous_levels, None\n",
    "                )\n",
    "                gp.build_model()\n",
    "                gp.find_MAP(progressbar=False)\n",
    "                \n",
    "            test_preds = gp.predict_points(\n",
    "                gp.parray(**test_ds.wide[[\"BP\", \"GC\"]].to_dict(orient=\"list\"))\n",
    "            ).get(\"r\")\n",
    "            train_preds = gp.predict_points(\n",
    "                gp.parray(**train_ds.wide[[\"BP\", \"GC\"]].to_dict(orient=\"list\"))\n",
    "            ).get(\"r\")\n",
    "        except LinAlgError:\n",
    "            continue\n",
    "\n",
    "        test_rmse = np.sqrt(np.mean((test_preds.μ - test_ds.wide[\"r\"]) ** 2))\n",
    "        train_rmse = np.sqrt(\n",
    "            np.mean((train_preds.μ - train_ds.wide[\"r\"]) ** 2)\n",
    "            \n",
    "        )\n",
    "\n",
    "        test_nlpd = -test_preds.dist.logpdf(test_ds.wide[\"r\"]).mean()\n",
    "        train_nlpd = -train_preds.dist.logpdf(train_ds.wide[\"r\"]).mean()\n",
    "\n",
    "        test_nlpd, train_nlpd, test_rmse, train_rmse\n",
    "\n",
    "        row = {\n",
    "            \"N_train\": i,\n",
    "            \"Iteration\": j,\n",
    "            \"Train_NLPD\": train_nlpd,\n",
    "            \"Train_RMSE\": train_rmse,\n",
    "            \"Test_NLPD\": test_nlpd,\n",
    "            \"Test_RMSE\": test_rmse,\n",
    "            \"TrainCode\": train_code,\n",
    "        }\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([row])])\n",
    "        df.to_csv(gen_pth / \"Ind_model_xval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (6, 0), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6), (6, 7), (6, 8), (6, 9), (11, 0), (11, 1), (11, 2), (11, 3), (11, 4), (11, 5), (11, 6), (11, 7), (11, 8), (11, 9), (16, 0), (16, 1), (16, 2), (16, 3), (16, 4), (16, 5), (16, 6), (16, 7), (16, 8), (16, 9), (21, 0), (21, 1), (21, 2), (21, 3), (21, 4), (21, 5), (21, 6), (21, 7), (21, 8), (21, 9), (26, 0), (26, 1), (26, 2), (26, 3), (26, 4), (26, 5), (26, 6), (26, 7), (26, 8), (26, 9), (31, 0), (31, 1), (31, 2), (31, 3), (31, 4), (31, 5), (31, 6), (31, 7), (31, 8), (31, 9), (36, 0), (36, 1), (36, 2), (36, 3), (36, 4), (36, 5), (36, 6)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4bc9994af441429c0c41cdade6fd40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training set size:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec20c3ff5158488abbd70c9139a1b13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2148bbb32c0444238fa5893c42ffece3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ae00d0188648398096c65a74848be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ffd3227da64fea9af2df36b310cd56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96e4a0a5e8f454b89c423f6661f83ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8edc428df88e403abe1c06a07ed4751c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85567b36b07f4e4482e2278fd96e9949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895f26372c3343c28d81db8d7f01ac75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "rows = []\n",
    "\n",
    "x = 0\n",
    "\n",
    "if (gen_pth / \"LMC_model_xval.csv\").exists():\n",
    "    df = pd.read_csv(gen_pth / \"LMC_model_xval.csv\")\n",
    "    print(df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist())\n",
    "else:\n",
    "    df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"N_train\",\n",
    "            \"Iteration\",\n",
    "            \"Train_NLPD\",\n",
    "            \"Train_RMSE\",\n",
    "            \"Test_NLPD\",\n",
    "            \"Test_RMSE\",\n",
    "            \"TrainCode\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "for i in tqdm(range(1, I + 1, 5), desc=\"Training set size\", leave=True):\n",
    "    for j in tqdm(range(J), desc=\"Iteration\", leave=False):\n",
    "\n",
    "        so_far = df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist()\n",
    "        if (i, j) in so_far:\n",
    "            continue\n",
    "\n",
    "        is_train = get_train_vec(j, i)\n",
    "        train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "        k = 0\n",
    "        while train_code in df[\"TrainCode\"].values:\n",
    "            is_train = get_train_vec(j * 1000 + k * I, i)\n",
    "            train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "            k += 1\n",
    "\n",
    "        train_data = pd.concat([static_data, xval_data.iloc[is_train]])\n",
    "        test_data = xval_data.iloc[~is_train]\n",
    "\n",
    "        train_ds = gmb.DataSet(\n",
    "            data=train_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        test_ds = gmb.DataSet(\n",
    "            data=test_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            gp = gmb.GP(train_ds).fit(\n",
    "                continuous_dims=[\"BP\", \"GC\"],\n",
    "                categorical_dims=[\"PrimerPair\", \"Reporter\"],\n",
    "                progressbar=False,\n",
    "            )\n",
    "\n",
    "            test_pa = gp.parray(**test_ds.wide[[\"BP\", \"GC\"]].to_dict(orient=\"list\"))\n",
    "            test_pa = gp.append_categorical_points(\n",
    "                test_pa, {\"PrimerPair\": \"FP004-RP004\", \"Reporter\": \"HEX\"}\n",
    "            )\n",
    "            test_preds = gp.predict_points(test_pa).get(\"r\")\n",
    "\n",
    "            train_pa = gp.parray(\n",
    "                **xval_data.iloc[is_train][[\"BP\", \"GC\"]].to_dict(orient=\"list\")\n",
    "            )\n",
    "            train_pa = gp.append_categorical_points(\n",
    "                train_pa, {\"PrimerPair\": \"FP004-RP004\", \"Reporter\": \"HEX\"}\n",
    "            )\n",
    "            train_preds = gp.predict_points(train_pa).get(\"r\")\n",
    "        except LinAlgError:\n",
    "            continue\n",
    "\n",
    "        test_rmse = np.sqrt(np.mean((test_preds.μ - test_ds.wide[\"r\"]) ** 2))\n",
    "        train_rmse = np.sqrt(\n",
    "            np.mean((train_preds.μ - xval_data.iloc[is_train][\"r\"]) ** 2)\n",
    "        )\n",
    "\n",
    "        test_nlpd = -test_preds.dist.logpdf(test_ds.wide[\"r\"]).mean()\n",
    "        train_nlpd = -train_preds.dist.logpdf(xval_data.iloc[is_train][\"r\"]).mean()\n",
    "\n",
    "        test_nlpd, train_nlpd, test_rmse, train_rmse\n",
    "\n",
    "        row = {\n",
    "            \"N_train\": i,\n",
    "            \"Iteration\": j,\n",
    "            \"Train_NLPD\": train_nlpd,\n",
    "            \"Train_RMSE\": train_rmse,\n",
    "            \"Test_NLPD\": test_nlpd,\n",
    "            \"Test_RMSE\": test_rmse,\n",
    "            \"TrainCode\": train_code,\n",
    "        }\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([row])])\n",
    "        df.to_csv(gen_pth / \"LMC_model_xval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d824a2fc7f3b4132bb485e8405f2da54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training set size:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8337bef6bfb42f8892c1c4a3f1967eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "rows = []\n",
    "\n",
    "x = 0\n",
    "\n",
    "if (gen_pth / \"LMC_model2_xval.csv\").exists():\n",
    "    df = pd.read_csv(gen_pth / \"LMC_model2_xval.csv\")\n",
    "    print(df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist())\n",
    "else:\n",
    "    df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"N_train\",\n",
    "            \"Iteration\",\n",
    "            \"Train_NLPD\",\n",
    "            \"Train_RMSE\",\n",
    "            \"Test_NLPD\",\n",
    "            \"Test_RMSE\",\n",
    "            \"TrainCode\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "for i in tqdm(range(1, I + 1, 5), desc=\"Training set size\", leave=True):\n",
    "    for j in tqdm(range(J), desc=\"Iteration\", leave=False):\n",
    "\n",
    "        so_far = df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist()\n",
    "        if (i, j) in so_far:\n",
    "            continue\n",
    "\n",
    "        is_train = get_train_vec(j, i)\n",
    "        train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "        k = 0\n",
    "        while train_code in df[\"TrainCode\"].values:\n",
    "            is_train = get_train_vec(j * 1000 + k * I, i)\n",
    "            train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "            k += 1\n",
    "\n",
    "        train_data = pd.concat([static_data, xval_data.iloc[is_train]])\n",
    "        test_data = xval_data.iloc[~is_train]\n",
    "\n",
    "        train_ds = gmb.DataSet(\n",
    "            data=train_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        test_ds = gmb.DataSet(\n",
    "            data=test_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            gp = gmb.GP(train_ds).fit(\n",
    "                continuous_dims=[\"BP\", \"GC\"],\n",
    "                categorical_dims=[\"PrimerPair\"],\n",
    "                progressbar=False,\n",
    "            )\n",
    "\n",
    "            test_pa = gp.parray(**test_ds.wide[[\"BP\", \"GC\"]].to_dict(orient=\"list\"))\n",
    "            test_pa = gp.append_categorical_points(\n",
    "                test_pa, {\"PrimerPair\": \"FP004-RP004\"}\n",
    "            )\n",
    "            test_preds = gp.predict_points(test_pa).get(\"r\")\n",
    "\n",
    "            train_pa = gp.parray(\n",
    "                **xval_data.iloc[is_train][[\"BP\", \"GC\"]].to_dict(orient=\"list\")\n",
    "            )\n",
    "            train_pa = gp.append_categorical_points(\n",
    "                train_pa, {\"PrimerPair\": \"FP004-RP004\"}\n",
    "            )\n",
    "            train_preds = gp.predict_points(train_pa).get(\"r\")\n",
    "        except LinAlgError:\n",
    "            continue\n",
    "\n",
    "        test_rmse = np.sqrt(np.mean((test_preds.μ - test_ds.wide[\"r\"]) ** 2))\n",
    "        train_rmse = np.sqrt(\n",
    "            np.mean((train_preds.μ - xval_data.iloc[is_train][\"r\"]) ** 2)\n",
    "        )\n",
    "\n",
    "        test_nlpd = -test_preds.dist.logpdf(test_ds.wide[\"r\"]).mean()\n",
    "        train_nlpd = -train_preds.dist.logpdf(xval_data.iloc[is_train][\"r\"]).mean()\n",
    "\n",
    "        test_nlpd, train_nlpd, test_rmse, train_rmse\n",
    "\n",
    "        row = {\n",
    "            \"N_train\": i,\n",
    "            \"Iteration\": j,\n",
    "            \"Train_NLPD\": train_nlpd,\n",
    "            \"Train_RMSE\": train_rmse,\n",
    "            \"Test_NLPD\": test_nlpd,\n",
    "            \"Test_RMSE\": test_rmse,\n",
    "            \"TrainCode\": train_code,\n",
    "        }\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([row])])\n",
    "        df.to_csv(gen_pth / \"LMC_model2_xval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "py,ipynb"
  },
  "kernelspec": {
   "display_name": "can_manuscript",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
