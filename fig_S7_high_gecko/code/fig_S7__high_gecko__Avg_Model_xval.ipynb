{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.use(\"Cairo\")  # for saving SVGs that Affinity Designer can parse\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib as pl\n",
    "import dill\n",
    "\n",
    "import candas as can\n",
    "import gumbi as gmb\n",
    "from candas.learn import ParameterSet\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "code_pth = pl.Path.cwd()  # for running in Jupyter\n",
    "# code_pth = pl.Path(__file__)  # for running in terminal\n",
    "fig_pth = code_pth.parent\n",
    "data_pth = fig_pth / \"data\"\n",
    "graph_pth = fig_pth / \"graphics\"\n",
    "graph_pth.mkdir(exist_ok=True)\n",
    "\n",
    "gen_pth = fig_pth / \"generated\"\n",
    "gen_pth.mkdir(exist_ok=True)\n",
    "\n",
    "plt.style.use(str(can.style.breve))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use('style.mplstyle')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from utils import savefig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = ParameterSet.load(data_pth / \"ADVI_ParameterSets_220528.pkl\")\n",
    "\n",
    "\n",
    "def make_pair(row):\n",
    "    return \"-\".join(sorted([row.FPrimer, row.RPrimer]))\n",
    "\n",
    "\n",
    "data = (\n",
    "    ps.wide.query('Metric == \"mean\"')\n",
    "    .astype({\"BP\": float})\n",
    "    .assign(PrimerPair=lambda df: df.apply(make_pair, axis=1))\n",
    "    .groupby([\"Target\", \"PrimerPair\", \"Reporter\"])\n",
    "    .mean(numeric_only=True)\n",
    "    .drop_duplicates()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "selected = (\n",
    "    data.groupby([\"PrimerPair\", \"Reporter\"])\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"Observations\"})\n",
    "    .sort_values(\"Observations\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ").iloc[[0, 1, 4, 5, 6, 8, 38, 39, 42]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_full = gmb.DataSet(\n",
    "    data=data,\n",
    "    outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "    log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "    logit_vars=[\"GC\"],\n",
    ")\n",
    "stdzr = ds_full.stdzr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data = data[\n",
    "            ~((data.PrimerPair == 'FP004-RP004') & (data.Reporter == 'HEX'))\n",
    "        ]\n",
    "\n",
    "xval_data = data[\n",
    "            (data.PrimerPair == 'FP004-RP004') & (data.Reporter == 'HEX')\n",
    "        ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 10\n",
    "i = 3\n",
    "I = len(xval_data)\n",
    "    \n",
    "def get_train_vec(x, i):\n",
    "    \"\"\"\n",
    "    Get a training vector for the cross-validation\n",
    "    \"\"\"\n",
    "    is_train = np.array([1]*i + [0]*(I-i)).astype(bool)\n",
    "    np.random.RandomState(x*I+i).shuffle(is_train)\n",
    "    return is_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (6, 0), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6), (6, 7), (6, 8), (6, 9), (11, 0), (11, 1), (11, 2), (11, 3), (11, 4), (11, 5), (11, 6), (11, 7), (11, 8), (11, 9), (16, 0), (16, 1), (16, 2), (16, 3), (16, 4), (16, 5), (16, 6), (16, 7), (16, 8), (16, 9), (21, 0), (21, 1), (21, 2), (21, 3), (21, 4), (21, 5), (21, 6), (21, 7), (21, 8), (21, 9), (26, 0), (26, 1), (26, 2), (26, 3), (26, 4), (26, 5), (26, 6), (26, 7), (26, 8), (26, 9), (31, 0), (31, 1), (31, 2), (31, 3), (31, 4), (31, 5), (31, 6), (31, 7), (31, 8), (31, 9), (36, 0), (36, 1), (36, 2), (36, 3), (36, 4), (36, 5), (36, 6), (36, 7), (36, 8), (36, 9)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141f5dbf4ff744999accfb7ed17918a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training set size:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7432d5efced41f68f4a2fdb804d0edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44faeef53174ff5a3365d15966db6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25753f42d574482a9dc026f361b3f3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaabaa13ef4b454193845d280efccbe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6c0b92f6644ae2a9296e998b60f12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188d4b71658447bd984ba709e9c3f36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88825e900fac4f288babdc141befe731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f141b042f14648bb84f9f8314f7fd3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "rows = []\n",
    "\n",
    "x = 0\n",
    "\n",
    "if (gen_pth / \"Avg_model_xval.csv\").exists():\n",
    "    df = pd.read_csv(gen_pth / \"Avg_model_xval.csv\")\n",
    "    print(df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist())\n",
    "else:\n",
    "    df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"N_train\",\n",
    "            \"Iteration\",\n",
    "            \"Train_NLPD\",\n",
    "            \"Train_RMSE\",\n",
    "            \"Test_NLPD\",\n",
    "            \"Test_RMSE\",\n",
    "            \"TrainCode\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "for i in tqdm(range(1, I + 1, 5), desc=\"Training set size\", leave=True):\n",
    "    for j in tqdm(range(J), desc=\"Iteration\", leave=False):\n",
    "        \n",
    "        so_far = df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist()\n",
    "        if (i, j) in so_far:\n",
    "            continue\n",
    "        \n",
    "        is_train = get_train_vec(j, i)\n",
    "        train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "        k = 0\n",
    "        while train_code in df[\"TrainCode\"].values:\n",
    "            is_train = get_train_vec(j*1000+k*I, i)\n",
    "            train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "            k += 1\n",
    "\n",
    "        train_data = pd.concat([static_data, xval_data.iloc[is_train]])\n",
    "        test_data = xval_data.iloc[~is_train]\n",
    "\n",
    "        train_ds = gmb.DataSet(\n",
    "            data=train_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        test_ds = gmb.DataSet(\n",
    "            data=test_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            gp = gmb.GP(train_ds).fit(\n",
    "                continuous_dims=[\"BP\", \"GC\"], progressbar=False\n",
    "            )\n",
    "            test_preds = gp.predict_points(\n",
    "                gp.parray(**test_ds.wide[[\"BP\", \"GC\"]].to_dict(orient=\"list\"))\n",
    "            ).get(\"r\")\n",
    "            train_preds = gp.predict_points(\n",
    "                gp.parray(**xval_data.iloc[is_train][[\"BP\", \"GC\"]].to_dict(orient=\"list\"))\n",
    "            ).get(\"r\")\n",
    "        except LinAlgError:\n",
    "            continue\n",
    "\n",
    "        test_rmse = np.sqrt(np.mean((test_preds.μ - test_ds.wide[\"r\"]) ** 2))\n",
    "        train_rmse = np.sqrt(\n",
    "            np.mean((train_preds.μ - xval_data.iloc[is_train][\"r\"]) ** 2)\n",
    "        )\n",
    "\n",
    "        test_nlpd = -test_preds.dist.logpdf(test_ds.wide[\"r\"]).mean()\n",
    "        train_nlpd = -train_preds.dist.logpdf(xval_data.iloc[is_train][\"r\"]).mean()\n",
    "\n",
    "        test_nlpd, train_nlpd, test_rmse, train_rmse\n",
    "\n",
    "        row = {\n",
    "            \"N_train\": i,\n",
    "            \"Iteration\": j,\n",
    "            \"Train_NLPD\": train_nlpd,\n",
    "            \"Train_RMSE\": train_rmse,\n",
    "            \"Test_NLPD\": test_nlpd,\n",
    "            \"Test_RMSE\": test_rmse,\n",
    "            \"TrainCode\": train_code,\n",
    "        }\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([row])])\n",
    "        df.to_csv(gen_pth / \"Avg_model_xval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (6, 0), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6), (6, 7), (6, 8), (6, 9), (11, 0), (11, 1), (11, 2), (11, 3), (11, 4), (11, 5), (11, 6), (11, 7), (11, 8), (11, 9), (16, 0), (16, 1), (16, 2), (16, 3), (16, 4), (16, 5), (16, 6), (16, 7), (16, 8), (16, 9), (21, 0), (21, 1), (21, 2), (21, 3), (21, 4), (21, 5), (21, 6), (21, 7), (21, 8), (21, 9), (26, 0), (26, 1), (26, 2), (26, 3), (26, 4), (26, 5), (26, 6), (26, 7), (26, 8), (26, 9), (31, 0), (31, 1), (31, 2), (31, 3), (31, 4), (31, 5), (31, 6), (31, 7), (31, 8), (31, 9), (36, 0), (36, 1), (36, 2), (36, 3), (36, 4), (36, 5), (36, 6), (36, 7), (36, 8), (36, 9)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5871f71e8f24bd584201fdcdcb9f5e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training set size:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f882c1f5c06b4310a2cc8e501569fc02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0d59a137ee4ed5809a8d1a9ac173a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79082a7f1c5d4872869487054b749bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7919ba6d4de047f18d5ab237d1ab48e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b00d67717d44e1a24ef16f749b1dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10dfe03968d459594747d3309c8d393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757df62b86044eb5a2527e76cc5b2ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3068a14033df4df79a31765d6bf32c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "rows = []\n",
    "\n",
    "x = 0\n",
    "\n",
    "if (gen_pth / \"Ind_model_xval.csv\").exists():\n",
    "    df = pd.read_csv(gen_pth / \"Ind_model_xval.csv\")\n",
    "    print(df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist())\n",
    "else:\n",
    "    df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"N_train\",\n",
    "            \"Iteration\",\n",
    "            \"Train_NLPD\",\n",
    "            \"Train_RMSE\",\n",
    "            \"Test_NLPD\",\n",
    "            \"Test_RMSE\",\n",
    "            \"TrainCode\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "for i in tqdm(range(1, I + 1, 5), desc=\"Training set size\", leave=True):\n",
    "    for j in tqdm(range(J), desc=\"Iteration\", leave=False):\n",
    "        \n",
    "        so_far = df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist()\n",
    "        if (i, j) in so_far:\n",
    "            continue\n",
    "        \n",
    "        is_train = get_train_vec(j, i)\n",
    "        train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "        k = 0\n",
    "        while train_code in df[\"TrainCode\"].values:\n",
    "            is_train = get_train_vec(j*1000+k*I, i)\n",
    "            train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "            k += 1\n",
    "\n",
    "        train_data = xval_data.iloc[is_train]\n",
    "        test_data = xval_data.iloc[~is_train]\n",
    "\n",
    "        train_ds = gmb.DataSet(\n",
    "            data=train_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        test_ds = gmb.DataSet(\n",
    "            data=test_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            if train_ds.wide.shape[0] > 1:\n",
    "                gp = gmb.GP(train_ds).fit(\n",
    "                    continuous_dims=[\"BP\", \"GC\"], progressbar=False\n",
    "                )\n",
    "            else:\n",
    "                gp = gmb.GP(train_ds)\n",
    "                gp.specify_model(continuous_dims=[\"BP\", \"GC\"])\n",
    "                gp.filter_dims = {}\n",
    "                gp.continuous_dims = [\"BP\", \"GC\"]\n",
    "                gp.continuous_levels = gp._parse_levels(gp.continuous_dims, None)\n",
    "                gp.continuous_coords = gp._parse_coordinates(\n",
    "                    gp.continuous_dims, gp.continuous_levels, None\n",
    "                )\n",
    "                gp.build_model()\n",
    "                gp.find_MAP(progressbar=False)\n",
    "                \n",
    "            test_preds = gp.predict_points(\n",
    "                gp.parray(**test_ds.wide[[\"BP\", \"GC\"]].to_dict(orient=\"list\"))\n",
    "            ).get(\"r\")\n",
    "            train_preds = gp.predict_points(\n",
    "                gp.parray(**train_ds.wide[[\"BP\", \"GC\"]].to_dict(orient=\"list\"))\n",
    "            ).get(\"r\")\n",
    "        except LinAlgError:\n",
    "            continue\n",
    "\n",
    "        test_rmse = np.sqrt(np.mean((test_preds.μ - test_ds.wide[\"r\"]) ** 2))\n",
    "        train_rmse = np.sqrt(\n",
    "            np.mean((train_preds.μ - train_ds.wide[\"r\"]) ** 2)\n",
    "            \n",
    "        )\n",
    "\n",
    "        test_nlpd = -test_preds.dist.logpdf(test_ds.wide[\"r\"]).mean()\n",
    "        train_nlpd = -train_preds.dist.logpdf(train_ds.wide[\"r\"]).mean()\n",
    "\n",
    "        test_nlpd, train_nlpd, test_rmse, train_rmse\n",
    "\n",
    "        row = {\n",
    "            \"N_train\": i,\n",
    "            \"Iteration\": j,\n",
    "            \"Train_NLPD\": train_nlpd,\n",
    "            \"Train_RMSE\": train_rmse,\n",
    "            \"Test_NLPD\": test_nlpd,\n",
    "            \"Test_RMSE\": test_rmse,\n",
    "            \"TrainCode\": train_code,\n",
    "        }\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([row])])\n",
    "        df.to_csv(gen_pth / \"Ind_model_xval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (6, 0), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6), (6, 7), (6, 8), (6, 9), (11, 0), (11, 1), (11, 2), (11, 3), (11, 4), (11, 5), (11, 6), (11, 7), (11, 8), (11, 9), (16, 0), (16, 1), (16, 2), (16, 3), (16, 4), (16, 5), (16, 6), (16, 7), (16, 8), (16, 9), (21, 0), (21, 1), (21, 2), (21, 3), (21, 4), (21, 5), (21, 6), (21, 7), (21, 8), (21, 9), (26, 0), (26, 1), (26, 2), (26, 3), (26, 4), (26, 5), (26, 6), (26, 7), (26, 8), (26, 9), (31, 0), (31, 1), (31, 2), (31, 3), (31, 4), (31, 5), (31, 6), (31, 7), (31, 8), (31, 9), (36, 0), (36, 1), (36, 2), (36, 3), (36, 4), (36, 5), (36, 6), (36, 7), (36, 8), (36, 9)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b881281054c4f17bceffab9fb425d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training set size:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215fad4b673741919fce917cd87e75e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2bd0218536439d91d94cbe5a28ecfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78676f8a3643434ab474df7f720a1aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ad61511444477dae271be49db04437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2612b21a505e4027bfba464d4008e167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b672e9dece04baaae4ea5edb80c0d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4513ed119e42f3b7782c8cef0eb21c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f52c4ec6d0f4d91a81f53cdb0e8b070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "rows = []\n",
    "\n",
    "x = 0\n",
    "\n",
    "if (gen_pth / \"LMC_model_xval.csv\").exists():\n",
    "    df = pd.read_csv(gen_pth / \"LMC_model_xval.csv\")\n",
    "    print(df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist())\n",
    "else:\n",
    "    df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"N_train\",\n",
    "            \"Iteration\",\n",
    "            \"Train_NLPD\",\n",
    "            \"Train_RMSE\",\n",
    "            \"Test_NLPD\",\n",
    "            \"Test_RMSE\",\n",
    "            \"TrainCode\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "for i in tqdm(range(1, I + 1, 5), desc=\"Training set size\", leave=True):\n",
    "    for j in tqdm(range(J), desc=\"Iteration\", leave=False):\n",
    "\n",
    "        so_far = df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist()\n",
    "        if (i, j) in so_far:\n",
    "            continue\n",
    "\n",
    "        is_train = get_train_vec(j, i)\n",
    "        train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "        k = 0\n",
    "        while train_code in df[\"TrainCode\"].values:\n",
    "            is_train = get_train_vec(j * 1000 + k * I, i)\n",
    "            train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "            k += 1\n",
    "\n",
    "        train_data = pd.concat([static_data, xval_data.iloc[is_train]])\n",
    "        test_data = xval_data.iloc[~is_train]\n",
    "\n",
    "        train_ds = gmb.DataSet(\n",
    "            data=train_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        test_ds = gmb.DataSet(\n",
    "            data=test_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            gp = gmb.GP(train_ds).fit(\n",
    "                continuous_dims=[\"BP\", \"GC\"],\n",
    "                categorical_dims=[\"PrimerPair\", \"Reporter\"],\n",
    "                progressbar=False,\n",
    "            )\n",
    "\n",
    "            test_pa = gp.parray(**test_ds.wide[[\"BP\", \"GC\"]].to_dict(orient=\"list\"))\n",
    "            test_pa = gp.append_categorical_points(\n",
    "                test_pa, {\"PrimerPair\": \"FP004-RP004\", \"Reporter\": \"HEX\"}\n",
    "            )\n",
    "            test_preds = gp.predict_points(test_pa).get(\"r\")\n",
    "\n",
    "            train_pa = gp.parray(\n",
    "                **xval_data.iloc[is_train][[\"BP\", \"GC\"]].to_dict(orient=\"list\")\n",
    "            )\n",
    "            train_pa = gp.append_categorical_points(\n",
    "                train_pa, {\"PrimerPair\": \"FP004-RP004\", \"Reporter\": \"HEX\"}\n",
    "            )\n",
    "            train_preds = gp.predict_points(train_pa).get(\"r\")\n",
    "        except LinAlgError:\n",
    "            continue\n",
    "\n",
    "        test_rmse = np.sqrt(np.mean((test_preds.μ - test_ds.wide[\"r\"]) ** 2))\n",
    "        train_rmse = np.sqrt(\n",
    "            np.mean((train_preds.μ - xval_data.iloc[is_train][\"r\"]) ** 2)\n",
    "        )\n",
    "\n",
    "        test_nlpd = -test_preds.dist.logpdf(test_ds.wide[\"r\"]).mean()\n",
    "        train_nlpd = -train_preds.dist.logpdf(xval_data.iloc[is_train][\"r\"]).mean()\n",
    "\n",
    "        test_nlpd, train_nlpd, test_rmse, train_rmse\n",
    "\n",
    "        row = {\n",
    "            \"N_train\": i,\n",
    "            \"Iteration\": j,\n",
    "            \"Train_NLPD\": train_nlpd,\n",
    "            \"Train_RMSE\": train_rmse,\n",
    "            \"Test_NLPD\": test_nlpd,\n",
    "            \"Test_RMSE\": test_rmse,\n",
    "            \"TrainCode\": train_code,\n",
    "        }\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([row])])\n",
    "        df.to_csv(gen_pth / \"LMC_model_xval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (6, 0), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6), (6, 7), (6, 8), (6, 9), (11, 0), (11, 1), (11, 2), (11, 3), (11, 4), (11, 5), (11, 6), (11, 7), (11, 8), (11, 9), (16, 0), (16, 1), (16, 2), (16, 3), (16, 4), (16, 5), (16, 6), (16, 7), (16, 8), (16, 9), (21, 0), (21, 1), (21, 2), (21, 3), (21, 4), (21, 5), (21, 6), (21, 7), (21, 8), (21, 9), (26, 0), (26, 1), (26, 2), (26, 3), (26, 4), (26, 5), (26, 6), (26, 7), (26, 8), (26, 9), (31, 0), (31, 1), (31, 2), (31, 3), (31, 4), (31, 5), (31, 6), (31, 7), (31, 8), (31, 9), (36, 0), (36, 1), (36, 2), (36, 3), (36, 4)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72dd7647654b4305b3f2a011b74a8335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training set size:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53941a44bbbd4d71b25d8c18d4395443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa1df5c24c94c93b5a0a6af99f119b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9258d98d09b54c24a136dceb2669e85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d9a3902e0b46d5aae10fd9adb642f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9853f5a5621f478a8fc2c4c750592f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ada3533fb384e8e93180c1ee85be427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e14069090f14ee38d1e3495471e0e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c1745c7d584efeb114d29d3d9463ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "rows = []\n",
    "\n",
    "x = 0\n",
    "\n",
    "if (gen_pth / \"LMC_model2_xval.csv\").exists():\n",
    "    df = pd.read_csv(gen_pth / \"LMC_model2_xval.csv\")\n",
    "    print(df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist())\n",
    "else:\n",
    "    df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"N_train\",\n",
    "            \"Iteration\",\n",
    "            \"Train_NLPD\",\n",
    "            \"Train_RMSE\",\n",
    "            \"Test_NLPD\",\n",
    "            \"Test_RMSE\",\n",
    "            \"TrainCode\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "for i in tqdm(range(1, I + 1, 5), desc=\"Training set size\", leave=True):\n",
    "    for j in tqdm(range(J), desc=\"Iteration\", leave=False):\n",
    "\n",
    "        so_far = df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist()\n",
    "        if (i, j) in so_far:\n",
    "            continue\n",
    "\n",
    "        is_train = get_train_vec(j, i)\n",
    "        train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "        k = 0\n",
    "        while train_code in df[\"TrainCode\"].values:\n",
    "            is_train = get_train_vec(j * 1000 + k * I, i)\n",
    "            train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "            k += 1\n",
    "\n",
    "        train_data = pd.concat([static_data, xval_data.iloc[is_train]])\n",
    "        test_data = xval_data.iloc[~is_train]\n",
    "\n",
    "        train_ds = gmb.DataSet(\n",
    "            data=train_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        test_ds = gmb.DataSet(\n",
    "            data=test_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            gp = gmb.GP(train_ds).fit(\n",
    "                continuous_dims=[\"BP\", \"GC\"],\n",
    "                categorical_dims=[\"PrimerPair\"],\n",
    "                progressbar=False,\n",
    "            )\n",
    "\n",
    "            test_pa = gp.parray(**test_ds.wide[[\"BP\", \"GC\"]].to_dict(orient=\"list\"))\n",
    "            test_pa = gp.append_categorical_points(\n",
    "                test_pa, {\"PrimerPair\": \"FP004-RP004\"}\n",
    "            )\n",
    "            test_preds = gp.predict_points(test_pa).get(\"r\")\n",
    "\n",
    "            train_pa = gp.parray(\n",
    "                **xval_data.iloc[is_train][[\"BP\", \"GC\"]].to_dict(orient=\"list\")\n",
    "            )\n",
    "            train_pa = gp.append_categorical_points(\n",
    "                train_pa, {\"PrimerPair\": \"FP004-RP004\"}\n",
    "            )\n",
    "            train_preds = gp.predict_points(train_pa).get(\"r\")\n",
    "        except LinAlgError:\n",
    "            continue\n",
    "\n",
    "        test_rmse = np.sqrt(np.mean((test_preds.μ - test_ds.wide[\"r\"]) ** 2))\n",
    "        train_rmse = np.sqrt(\n",
    "            np.mean((train_preds.μ - xval_data.iloc[is_train][\"r\"]) ** 2)\n",
    "        )\n",
    "\n",
    "        test_nlpd = -test_preds.dist.logpdf(test_ds.wide[\"r\"]).mean()\n",
    "        train_nlpd = -train_preds.dist.logpdf(xval_data.iloc[is_train][\"r\"]).mean()\n",
    "\n",
    "        test_nlpd, train_nlpd, test_rmse, train_rmse\n",
    "\n",
    "        row = {\n",
    "            \"N_train\": i,\n",
    "            \"Iteration\": j,\n",
    "            \"Train_NLPD\": train_nlpd,\n",
    "            \"Train_RMSE\": train_rmse,\n",
    "            \"Test_NLPD\": test_nlpd,\n",
    "            \"Test_RMSE\": test_rmse,\n",
    "            \"TrainCode\": train_code,\n",
    "        }\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([row])])\n",
    "        df.to_csv(gen_pth / \"LMC_model2_xval.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "py,ipynb"
  },
  "kernelspec": {
   "display_name": "can_manuscript",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
