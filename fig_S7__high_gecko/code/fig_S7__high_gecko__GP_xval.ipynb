{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.use(\"Cairo\")  # for saving SVGs that Affinity Designer can parse\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib as pl\n",
    "import dill\n",
    "\n",
    "import candas as can\n",
    "import gumbi as gmb\n",
    "from candas.learn import ParameterSet\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "code_pth = pl.Path.cwd()  # for running in Jupyter\n",
    "# code_pth = pl.Path(__file__)  # for running in terminal\n",
    "fig_pth = code_pth.parent\n",
    "data_pth = fig_pth / \"data\"\n",
    "graph_pth = fig_pth / \"graphics\"\n",
    "graph_pth.mkdir(exist_ok=True)\n",
    "\n",
    "gen_pth = fig_pth / \"generated\"\n",
    "gen_pth.mkdir(exist_ok=True)\n",
    "\n",
    "plt.style.use(str(can.style.breve))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use('style.mplstyle')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from utils import savefig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = ParameterSet.load(data_pth / \"ADVI_ParameterSets_220528.pkl\")\n",
    "\n",
    "\n",
    "def make_pair(row):\n",
    "    return \"-\".join(sorted([row.FPrimer, row.RPrimer]))\n",
    "\n",
    "\n",
    "data = (\n",
    "    ps.wide.query('Metric == \"mean\"')\n",
    "    .astype({\"BP\": float})\n",
    "    .assign(PrimerPair=lambda df: df.apply(make_pair, axis=1))\n",
    "    .groupby([\"Target\", \"PrimerPair\", \"Reporter\"])\n",
    "    .mean(numeric_only=True)\n",
    "    .drop_duplicates()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "selected = (\n",
    "    data.groupby([\"PrimerPair\", \"Reporter\"])\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"Observations\"})\n",
    "    .sort_values(\"Observations\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ").iloc[[0, 1, 4, 5, 6, 8, 38, 39, 42]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>PrimerPair</th>\n",
       "      <th>Reporter</th>\n",
       "      <th>Well</th>\n",
       "      <th>Copies</th>\n",
       "      <th>lg10_Copies</th>\n",
       "      <th>BP</th>\n",
       "      <th>GC</th>\n",
       "      <th>F0_lg</th>\n",
       "      <th>K</th>\n",
       "      <th>m</th>\n",
       "      <th>r</th>\n",
       "      <th>ρ</th>\n",
       "      <th>τ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S036.0</td>\n",
       "      <td>FP002-RP002</td>\n",
       "      <td>FAM</td>\n",
       "      <td>73.5</td>\n",
       "      <td>2.222200e+06</td>\n",
       "      <td>5.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>-4.587599</td>\n",
       "      <td>0.886769</td>\n",
       "      <td>0.014093</td>\n",
       "      <td>0.689985</td>\n",
       "      <td>0.241540</td>\n",
       "      <td>22.071664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S036.0</td>\n",
       "      <td>FP002-RP002</td>\n",
       "      <td>SYBR</td>\n",
       "      <td>289.5</td>\n",
       "      <td>1.587301e+07</td>\n",
       "      <td>5.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>-4.838178</td>\n",
       "      <td>2.538432</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.721427</td>\n",
       "      <td>0.229745</td>\n",
       "      <td>22.181675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S036.1</td>\n",
       "      <td>FP002-RP002</td>\n",
       "      <td>HEX</td>\n",
       "      <td>76.5</td>\n",
       "      <td>1.587301e+07</td>\n",
       "      <td>5.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>-5.625271</td>\n",
       "      <td>0.506225</td>\n",
       "      <td>0.008196</td>\n",
       "      <td>0.703616</td>\n",
       "      <td>0.222723</td>\n",
       "      <td>26.521073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S036.1</td>\n",
       "      <td>FP002-RP002</td>\n",
       "      <td>SYBR</td>\n",
       "      <td>292.5</td>\n",
       "      <td>1.587301e+07</td>\n",
       "      <td>5.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>-5.176247</td>\n",
       "      <td>2.562074</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.719332</td>\n",
       "      <td>0.224679</td>\n",
       "      <td>23.864819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S036.2</td>\n",
       "      <td>FP002-RP002</td>\n",
       "      <td>HEX</td>\n",
       "      <td>79.5</td>\n",
       "      <td>1.587301e+07</td>\n",
       "      <td>5.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>-5.521462</td>\n",
       "      <td>0.520119</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>0.749434</td>\n",
       "      <td>0.208817</td>\n",
       "      <td>24.461466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>S073.2.5</td>\n",
       "      <td>FP016-RP016</td>\n",
       "      <td>HEX</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.851850e+07</td>\n",
       "      <td>5.5</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.596026</td>\n",
       "      <td>-3.903683</td>\n",
       "      <td>0.570874</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>0.576920</td>\n",
       "      <td>0.298942</td>\n",
       "      <td>22.439724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>S073.2.6</td>\n",
       "      <td>FP016-RP016</td>\n",
       "      <td>HEX</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1.851850e+07</td>\n",
       "      <td>5.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>-5.710324</td>\n",
       "      <td>0.602489</td>\n",
       "      <td>0.007801</td>\n",
       "      <td>0.956558</td>\n",
       "      <td>0.139655</td>\n",
       "      <td>19.865759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>S073.2.7</td>\n",
       "      <td>FP016-RP016</td>\n",
       "      <td>HEX</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.851850e+07</td>\n",
       "      <td>5.5</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.430380</td>\n",
       "      <td>-5.274072</td>\n",
       "      <td>0.565490</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>0.857931</td>\n",
       "      <td>0.175466</td>\n",
       "      <td>20.399947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>S_PRDM1_WTa</td>\n",
       "      <td>FP003-RP003</td>\n",
       "      <td>HEX</td>\n",
       "      <td>191.0</td>\n",
       "      <td>2.525252e+07</td>\n",
       "      <td>5.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.525773</td>\n",
       "      <td>-4.581234</td>\n",
       "      <td>0.547564</td>\n",
       "      <td>0.021581</td>\n",
       "      <td>0.634075</td>\n",
       "      <td>0.265075</td>\n",
       "      <td>23.981282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>S_PRDM1_WTb</td>\n",
       "      <td>FP003-RP008</td>\n",
       "      <td>HEX</td>\n",
       "      <td>194.5</td>\n",
       "      <td>2.525252e+07</td>\n",
       "      <td>5.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.506024</td>\n",
       "      <td>-4.826496</td>\n",
       "      <td>0.563747</td>\n",
       "      <td>0.035161</td>\n",
       "      <td>0.736384</td>\n",
       "      <td>0.222928</td>\n",
       "      <td>21.817540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>368 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Target   PrimerPair Reporter   Well        Copies  lg10_Copies  \\\n",
       "0         S036.0  FP002-RP002      FAM   73.5  2.222200e+06          5.0   \n",
       "1         S036.0  FP002-RP002     SYBR  289.5  1.587301e+07          5.0   \n",
       "2         S036.1  FP002-RP002      HEX   76.5  1.587301e+07          5.0   \n",
       "3         S036.1  FP002-RP002     SYBR  292.5  1.587301e+07          5.0   \n",
       "4         S036.2  FP002-RP002      HEX   79.5  1.587301e+07          5.0   \n",
       "..           ...          ...      ...    ...           ...          ...   \n",
       "363     S073.2.5  FP016-RP016      HEX  154.0  1.851850e+07          5.5   \n",
       "364     S073.2.6  FP016-RP016      HEX  155.0  1.851850e+07          5.5   \n",
       "365     S073.2.7  FP016-RP016      HEX  156.0  1.851850e+07          5.5   \n",
       "366  S_PRDM1_WTa  FP003-RP003      HEX  191.0  2.525252e+07          5.0   \n",
       "367  S_PRDM1_WTb  FP003-RP008      HEX  194.5  2.525252e+07          5.0   \n",
       "\n",
       "        BP        GC     F0_lg         K         m         r         ρ  \\\n",
       "0    108.0  0.481481 -4.587599  0.886769  0.014093  0.689985  0.241540   \n",
       "1    108.0  0.481481 -4.838178  2.538432  0.000193  0.721427  0.229745   \n",
       "2    108.0  0.481481 -5.625271  0.506225  0.008196  0.703616  0.222723   \n",
       "3    108.0  0.481481 -5.176247  2.562074  0.001357  0.719332  0.224679   \n",
       "4     88.0  0.431818 -5.521462  0.520119  0.007947  0.749434  0.208817   \n",
       "..     ...       ...       ...       ...       ...       ...       ...   \n",
       "363  151.0  0.596026 -3.903683  0.570874  0.008261  0.576920  0.298942   \n",
       "364   35.0  0.457143 -5.710324  0.602489  0.007801  0.956558  0.139655   \n",
       "365   79.0  0.430380 -5.274072  0.565490  0.008499  0.857931  0.175466   \n",
       "366   97.0  0.525773 -4.581234  0.547564  0.021581  0.634075  0.265075   \n",
       "367   83.0  0.506024 -4.826496  0.563747  0.035161  0.736384  0.222928   \n",
       "\n",
       "             τ  \n",
       "0    22.071664  \n",
       "1    22.181675  \n",
       "2    26.521073  \n",
       "3    23.864819  \n",
       "4    24.461466  \n",
       "..         ...  \n",
       "363  22.439724  \n",
       "364  19.865759  \n",
       "365  20.399947  \n",
       "366  23.981282  \n",
       "367  21.817540  \n",
       "\n",
       "[368 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_full = gmb.DataSet(\n",
    "    data=data,\n",
    "    outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "    log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "    logit_vars=[\"GC\"],\n",
    ")\n",
    "stdzr = ds_full.stdzr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data = data[\n",
    "            ~((data.PrimerPair == 'FP004-RP004') & (data.Reporter == 'HEX'))\n",
    "        ]\n",
    "\n",
    "xval_data = data[\n",
    "            (data.PrimerPair == 'FP004-RP004') & (data.Reporter == 'HEX')\n",
    "        ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 10\n",
    "i = 3\n",
    "I = len(xval_data)\n",
    "    \n",
    "def get_train_vec(x, i):\n",
    "    \"\"\"\n",
    "    Get a training vector for the cross-validation\n",
    "    \"\"\"\n",
    "    is_train = np.array([1]*i + [0]*(I-i)).astype(bool)\n",
    "    np.random.RandomState(x*I+i).shuffle(is_train)\n",
    "    return is_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (6, 0), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6), (6, 7), (6, 8), (6, 9), (11, 0), (11, 1), (11, 2), (11, 3), (11, 4), (11, 5), (11, 6), (11, 7), (11, 8), (11, 9), (16, 0), (16, 1), (16, 2), (16, 3), (16, 4), (16, 5), (16, 6), (16, 7), (16, 8), (16, 9), (21, 0), (21, 1), (21, 2), (21, 3), (21, 4), (21, 5), (21, 6), (21, 7), (21, 8), (21, 9), (26, 0), (26, 1), (26, 2), (26, 3), (26, 4), (26, 5), (26, 6), (26, 7), (26, 8), (26, 9), (31, 0), (31, 1), (31, 2), (31, 3), (31, 4), (31, 5), (31, 6), (31, 7), (31, 8), (31, 9), (36, 0), (36, 1), (36, 2), (36, 3), (36, 4), (36, 5), (36, 6), (36, 7), (36, 8), (36, 9)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141f5dbf4ff744999accfb7ed17918a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training set size:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7432d5efced41f68f4a2fdb804d0edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44faeef53174ff5a3365d15966db6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25753f42d574482a9dc026f361b3f3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaabaa13ef4b454193845d280efccbe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6c0b92f6644ae2a9296e998b60f12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188d4b71658447bd984ba709e9c3f36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88825e900fac4f288babdc141befe731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f141b042f14648bb84f9f8314f7fd3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "rows = []\n",
    "\n",
    "x = 0\n",
    "\n",
    "if (gen_pth / \"Avg_model_xval.csv\").exists():\n",
    "    df = pd.read_csv(gen_pth / \"Avg_model_xval.csv\")\n",
    "    print(df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist())\n",
    "else:\n",
    "    df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"N_train\",\n",
    "            \"Iteration\",\n",
    "            \"Train_NLPD\",\n",
    "            \"Train_RMSE\",\n",
    "            \"Test_NLPD\",\n",
    "            \"Test_RMSE\",\n",
    "            \"TrainCode\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "for i in tqdm(range(1, I + 1, 5), desc=\"Training set size\", leave=True):\n",
    "    for j in tqdm(range(J), desc=\"Iteration\", leave=False):\n",
    "        \n",
    "        so_far = df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist()\n",
    "        if (i, j) in so_far:\n",
    "            continue\n",
    "        \n",
    "        is_train = get_train_vec(j, i)\n",
    "        train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "        k = 0\n",
    "        while train_code in df[\"TrainCode\"].values:\n",
    "            is_train = get_train_vec(j*1000+k*I, i)\n",
    "            train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "            k += 1\n",
    "\n",
    "        train_data = pd.concat([static_data, xval_data.iloc[is_train]])\n",
    "        test_data = xval_data.iloc[~is_train]\n",
    "\n",
    "        train_ds = gmb.DataSet(\n",
    "            data=train_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        test_ds = gmb.DataSet(\n",
    "            data=test_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            gp = gmb.GP(train_ds).fit(\n",
    "                continuous_dims=[\"BP\", \"GC\"], progressbar=False\n",
    "            )\n",
    "            test_preds = gp.predict_points(\n",
    "                gp.parray(**test_ds.wide[[\"BP\", \"GC\"]].to_dict(orient=\"list\"))\n",
    "            ).get(\"r\")\n",
    "            train_preds = gp.predict_points(\n",
    "                gp.parray(**xval_data.iloc[is_train][[\"BP\", \"GC\"]].to_dict(orient=\"list\"))\n",
    "            ).get(\"r\")\n",
    "        except LinAlgError:\n",
    "            continue\n",
    "\n",
    "        test_rmse = np.sqrt(np.mean((test_preds.μ - test_ds.wide[\"r\"]) ** 2))\n",
    "        train_rmse = np.sqrt(\n",
    "            np.mean((train_preds.μ - xval_data.iloc[is_train][\"r\"]) ** 2)\n",
    "        )\n",
    "\n",
    "        test_nlpd = -test_preds.dist.logpdf(test_ds.wide[\"r\"]).mean()\n",
    "        train_nlpd = -train_preds.dist.logpdf(xval_data.iloc[is_train][\"r\"]).mean()\n",
    "\n",
    "        test_nlpd, train_nlpd, test_rmse, train_rmse\n",
    "\n",
    "        row = {\n",
    "            \"N_train\": i,\n",
    "            \"Iteration\": j,\n",
    "            \"Train_NLPD\": train_nlpd,\n",
    "            \"Train_RMSE\": train_rmse,\n",
    "            \"Test_NLPD\": test_nlpd,\n",
    "            \"Test_RMSE\": test_rmse,\n",
    "            \"TrainCode\": train_code,\n",
    "        }\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([row])])\n",
    "        df.to_csv(gen_pth / \"Avg_model_xval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (6, 0), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6), (6, 7), (6, 8), (6, 9), (11, 0), (11, 1), (11, 2), (11, 3), (11, 4), (11, 5), (11, 6), (11, 7), (11, 8), (11, 9), (16, 0), (16, 1), (16, 2), (16, 3), (16, 4), (16, 5), (16, 6), (16, 7), (16, 8), (16, 9), (21, 0), (21, 1), (21, 2), (21, 3), (21, 4), (21, 5), (21, 6), (21, 7), (21, 8), (21, 9), (26, 0), (26, 1), (26, 2), (26, 3), (26, 4), (26, 5), (26, 6), (26, 7), (26, 8), (26, 9), (31, 0), (31, 1), (31, 2), (31, 3), (31, 4), (31, 5), (31, 6), (31, 7), (31, 8), (31, 9), (36, 0), (36, 1), (36, 2), (36, 3), (36, 4), (36, 5), (36, 6), (36, 7), (36, 8), (36, 9)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5871f71e8f24bd584201fdcdcb9f5e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training set size:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f882c1f5c06b4310a2cc8e501569fc02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0d59a137ee4ed5809a8d1a9ac173a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79082a7f1c5d4872869487054b749bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7919ba6d4de047f18d5ab237d1ab48e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b00d67717d44e1a24ef16f749b1dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10dfe03968d459594747d3309c8d393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757df62b86044eb5a2527e76cc5b2ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3068a14033df4df79a31765d6bf32c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "rows = []\n",
    "\n",
    "x = 0\n",
    "\n",
    "if (gen_pth / \"Ind_model_xval.csv\").exists():\n",
    "    df = pd.read_csv(gen_pth / \"Ind_model_xval.csv\")\n",
    "    print(df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist())\n",
    "else:\n",
    "    df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"N_train\",\n",
    "            \"Iteration\",\n",
    "            \"Train_NLPD\",\n",
    "            \"Train_RMSE\",\n",
    "            \"Test_NLPD\",\n",
    "            \"Test_RMSE\",\n",
    "            \"TrainCode\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "for i in tqdm(range(1, I + 1, 5), desc=\"Training set size\", leave=True):\n",
    "    for j in tqdm(range(J), desc=\"Iteration\", leave=False):\n",
    "        \n",
    "        so_far = df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist()\n",
    "        if (i, j) in so_far:\n",
    "            continue\n",
    "        \n",
    "        is_train = get_train_vec(j, i)\n",
    "        train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "        k = 0\n",
    "        while train_code in df[\"TrainCode\"].values:\n",
    "            is_train = get_train_vec(j*1000+k*I, i)\n",
    "            train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "            k += 1\n",
    "\n",
    "        train_data = xval_data.iloc[is_train]\n",
    "        test_data = xval_data.iloc[~is_train]\n",
    "\n",
    "        train_ds = gmb.DataSet(\n",
    "            data=train_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        test_ds = gmb.DataSet(\n",
    "            data=test_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            if train_ds.wide.shape[0] > 1:\n",
    "                gp = gmb.GP(train_ds).fit(\n",
    "                    continuous_dims=[\"BP\", \"GC\"], progressbar=False\n",
    "                )\n",
    "            else:\n",
    "                gp = gmb.GP(train_ds)\n",
    "                gp.specify_model(continuous_dims=[\"BP\", \"GC\"])\n",
    "                gp.filter_dims = {}\n",
    "                gp.continuous_dims = [\"BP\", \"GC\"]\n",
    "                gp.continuous_levels = gp._parse_levels(gp.continuous_dims, None)\n",
    "                gp.continuous_coords = gp._parse_coordinates(\n",
    "                    gp.continuous_dims, gp.continuous_levels, None\n",
    "                )\n",
    "                gp.build_model()\n",
    "                gp.find_MAP(progressbar=False)\n",
    "                \n",
    "            test_preds = gp.predict_points(\n",
    "                gp.parray(**test_ds.wide[[\"BP\", \"GC\"]].to_dict(orient=\"list\"))\n",
    "            ).get(\"r\")\n",
    "            train_preds = gp.predict_points(\n",
    "                gp.parray(**train_ds.wide[[\"BP\", \"GC\"]].to_dict(orient=\"list\"))\n",
    "            ).get(\"r\")\n",
    "        except LinAlgError:\n",
    "            continue\n",
    "\n",
    "        test_rmse = np.sqrt(np.mean((test_preds.μ - test_ds.wide[\"r\"]) ** 2))\n",
    "        train_rmse = np.sqrt(\n",
    "            np.mean((train_preds.μ - train_ds.wide[\"r\"]) ** 2)\n",
    "            \n",
    "        )\n",
    "\n",
    "        test_nlpd = -test_preds.dist.logpdf(test_ds.wide[\"r\"]).mean()\n",
    "        train_nlpd = -train_preds.dist.logpdf(train_ds.wide[\"r\"]).mean()\n",
    "\n",
    "        test_nlpd, train_nlpd, test_rmse, train_rmse\n",
    "\n",
    "        row = {\n",
    "            \"N_train\": i,\n",
    "            \"Iteration\": j,\n",
    "            \"Train_NLPD\": train_nlpd,\n",
    "            \"Train_RMSE\": train_rmse,\n",
    "            \"Test_NLPD\": test_nlpd,\n",
    "            \"Test_RMSE\": test_rmse,\n",
    "            \"TrainCode\": train_code,\n",
    "        }\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([row])])\n",
    "        df.to_csv(gen_pth / \"Ind_model_xval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (6, 0), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6), (6, 7), (6, 8), (6, 9), (11, 0), (11, 1), (11, 2), (11, 3), (11, 4), (11, 5), (11, 6), (11, 7), (11, 8), (11, 9), (16, 0), (16, 1), (16, 2), (16, 3), (16, 4), (16, 5), (16, 6), (16, 7), (16, 8), (16, 9), (21, 0), (21, 1), (21, 2), (21, 3), (21, 4), (21, 5), (21, 6), (21, 7), (21, 8), (21, 9), (26, 0), (26, 1), (26, 2), (26, 3), (26, 4), (26, 5), (26, 6), (26, 7), (26, 8), (26, 9), (31, 0), (31, 1), (31, 2), (31, 3), (31, 4), (31, 5), (31, 6), (31, 7), (31, 8), (31, 9), (36, 0), (36, 1), (36, 2), (36, 3), (36, 4), (36, 5), (36, 6), (36, 7), (36, 8), (36, 9)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b881281054c4f17bceffab9fb425d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training set size:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215fad4b673741919fce917cd87e75e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2bd0218536439d91d94cbe5a28ecfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78676f8a3643434ab474df7f720a1aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ad61511444477dae271be49db04437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2612b21a505e4027bfba464d4008e167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b672e9dece04baaae4ea5edb80c0d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4513ed119e42f3b7782c8cef0eb21c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f52c4ec6d0f4d91a81f53cdb0e8b070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "rows = []\n",
    "\n",
    "x = 0\n",
    "\n",
    "if (gen_pth / \"LMC_model_xval.csv\").exists():\n",
    "    df = pd.read_csv(gen_pth / \"LMC_model_xval.csv\")\n",
    "    print(df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist())\n",
    "else:\n",
    "    df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"N_train\",\n",
    "            \"Iteration\",\n",
    "            \"Train_NLPD\",\n",
    "            \"Train_RMSE\",\n",
    "            \"Test_NLPD\",\n",
    "            \"Test_RMSE\",\n",
    "            \"TrainCode\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "for i in tqdm(range(1, I + 1, 5), desc=\"Training set size\", leave=True):\n",
    "    for j in tqdm(range(J), desc=\"Iteration\", leave=False):\n",
    "\n",
    "        so_far = df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist()\n",
    "        if (i, j) in so_far:\n",
    "            continue\n",
    "\n",
    "        is_train = get_train_vec(j, i)\n",
    "        train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "        k = 0\n",
    "        while train_code in df[\"TrainCode\"].values:\n",
    "            is_train = get_train_vec(j * 1000 + k * I, i)\n",
    "            train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "            k += 1\n",
    "\n",
    "        train_data = pd.concat([static_data, xval_data.iloc[is_train]])\n",
    "        test_data = xval_data.iloc[~is_train]\n",
    "\n",
    "        train_ds = gmb.DataSet(\n",
    "            data=train_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        test_ds = gmb.DataSet(\n",
    "            data=test_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            gp = gmb.GP(train_ds).fit(\n",
    "                continuous_dims=[\"BP\", \"GC\"],\n",
    "                categorical_dims=[\"PrimerPair\", \"Reporter\"],\n",
    "                progressbar=False,\n",
    "            )\n",
    "\n",
    "            test_pa = gp.parray(**test_ds.wide[[\"BP\", \"GC\"]].to_dict(orient=\"list\"))\n",
    "            test_pa = gp.append_categorical_points(\n",
    "                test_pa, {\"PrimerPair\": \"FP004-RP004\", \"Reporter\": \"HEX\"}\n",
    "            )\n",
    "            test_preds = gp.predict_points(test_pa).get(\"r\")\n",
    "\n",
    "            train_pa = gp.parray(\n",
    "                **xval_data.iloc[is_train][[\"BP\", \"GC\"]].to_dict(orient=\"list\")\n",
    "            )\n",
    "            train_pa = gp.append_categorical_points(\n",
    "                train_pa, {\"PrimerPair\": \"FP004-RP004\", \"Reporter\": \"HEX\"}\n",
    "            )\n",
    "            train_preds = gp.predict_points(train_pa).get(\"r\")\n",
    "        except LinAlgError:\n",
    "            continue\n",
    "\n",
    "        test_rmse = np.sqrt(np.mean((test_preds.μ - test_ds.wide[\"r\"]) ** 2))\n",
    "        train_rmse = np.sqrt(\n",
    "            np.mean((train_preds.μ - xval_data.iloc[is_train][\"r\"]) ** 2)\n",
    "        )\n",
    "\n",
    "        test_nlpd = -test_preds.dist.logpdf(test_ds.wide[\"r\"]).mean()\n",
    "        train_nlpd = -train_preds.dist.logpdf(xval_data.iloc[is_train][\"r\"]).mean()\n",
    "\n",
    "        test_nlpd, train_nlpd, test_rmse, train_rmse\n",
    "\n",
    "        row = {\n",
    "            \"N_train\": i,\n",
    "            \"Iteration\": j,\n",
    "            \"Train_NLPD\": train_nlpd,\n",
    "            \"Train_RMSE\": train_rmse,\n",
    "            \"Test_NLPD\": test_nlpd,\n",
    "            \"Test_RMSE\": test_rmse,\n",
    "            \"TrainCode\": train_code,\n",
    "        }\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([row])])\n",
    "        df.to_csv(gen_pth / \"LMC_model_xval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (6, 0), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6), (6, 7), (6, 8), (6, 9), (11, 0), (11, 1), (11, 2), (11, 3), (11, 4), (11, 5), (11, 6), (11, 7), (11, 8), (11, 9), (16, 0), (16, 1), (16, 2), (16, 3), (16, 4), (16, 5), (16, 6), (16, 7), (16, 8), (16, 9), (21, 0), (21, 1), (21, 2), (21, 3), (21, 4), (21, 5), (21, 6), (21, 7), (21, 8), (21, 9), (26, 0), (26, 1), (26, 2), (26, 3), (26, 4), (26, 5), (26, 6), (26, 7), (26, 8), (26, 9), (31, 0), (31, 1), (31, 2), (31, 3), (31, 4), (31, 5), (31, 6), (31, 7), (31, 8), (31, 9), (36, 0), (36, 1), (36, 2), (36, 3), (36, 4)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72dd7647654b4305b3f2a011b74a8335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training set size:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53941a44bbbd4d71b25d8c18d4395443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa1df5c24c94c93b5a0a6af99f119b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9258d98d09b54c24a136dceb2669e85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d9a3902e0b46d5aae10fd9adb642f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9853f5a5621f478a8fc2c4c750592f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ada3533fb384e8e93180c1ee85be427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e14069090f14ee38d1e3495471e0e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c1745c7d584efeb114d29d3d9463ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "rows = []\n",
    "\n",
    "x = 0\n",
    "\n",
    "if (gen_pth / \"LMC_model2_xval.csv\").exists():\n",
    "    df = pd.read_csv(gen_pth / \"LMC_model2_xval.csv\")\n",
    "    print(df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist())\n",
    "else:\n",
    "    df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"N_train\",\n",
    "            \"Iteration\",\n",
    "            \"Train_NLPD\",\n",
    "            \"Train_RMSE\",\n",
    "            \"Test_NLPD\",\n",
    "            \"Test_RMSE\",\n",
    "            \"TrainCode\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "for i in tqdm(range(1, I + 1, 5), desc=\"Training set size\", leave=True):\n",
    "    for j in tqdm(range(J), desc=\"Iteration\", leave=False):\n",
    "\n",
    "        so_far = df[[\"N_train\", \"Iteration\"]].astype(int).apply(tuple, axis=1).tolist()\n",
    "        if (i, j) in so_far:\n",
    "            continue\n",
    "\n",
    "        is_train = get_train_vec(j, i)\n",
    "        train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "        k = 0\n",
    "        while train_code in df[\"TrainCode\"].values:\n",
    "            is_train = get_train_vec(j * 1000 + k * I, i)\n",
    "            train_code = \"\".join(is_train.astype(int).astype(str))\n",
    "            k += 1\n",
    "\n",
    "        train_data = pd.concat([static_data, xval_data.iloc[is_train]])\n",
    "        test_data = xval_data.iloc[~is_train]\n",
    "\n",
    "        train_ds = gmb.DataSet(\n",
    "            data=train_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        test_ds = gmb.DataSet(\n",
    "            data=test_data,\n",
    "            outputs=[\"F0_lg\", \"r\", \"K\", \"m\"],\n",
    "            log_vars=[\"BP\", \"K\", \"m\", \"r\"],\n",
    "            logit_vars=[\"GC\"],\n",
    "            stdzr=stdzr,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            gp = gmb.GP(train_ds).fit(\n",
    "                continuous_dims=[\"BP\", \"GC\"],\n",
    "                categorical_dims=[\"PrimerPair\"],\n",
    "                progressbar=False,\n",
    "            )\n",
    "\n",
    "            test_pa = gp.parray(**test_ds.wide[[\"BP\", \"GC\"]].to_dict(orient=\"list\"))\n",
    "            test_pa = gp.append_categorical_points(\n",
    "                test_pa, {\"PrimerPair\": \"FP004-RP004\"}\n",
    "            )\n",
    "            test_preds = gp.predict_points(test_pa).get(\"r\")\n",
    "\n",
    "            train_pa = gp.parray(\n",
    "                **xval_data.iloc[is_train][[\"BP\", \"GC\"]].to_dict(orient=\"list\")\n",
    "            )\n",
    "            train_pa = gp.append_categorical_points(\n",
    "                train_pa, {\"PrimerPair\": \"FP004-RP004\"}\n",
    "            )\n",
    "            train_preds = gp.predict_points(train_pa).get(\"r\")\n",
    "        except LinAlgError:\n",
    "            continue\n",
    "\n",
    "        test_rmse = np.sqrt(np.mean((test_preds.μ - test_ds.wide[\"r\"]) ** 2))\n",
    "        train_rmse = np.sqrt(\n",
    "            np.mean((train_preds.μ - xval_data.iloc[is_train][\"r\"]) ** 2)\n",
    "        )\n",
    "\n",
    "        test_nlpd = -test_preds.dist.logpdf(test_ds.wide[\"r\"]).mean()\n",
    "        train_nlpd = -train_preds.dist.logpdf(xval_data.iloc[is_train][\"r\"]).mean()\n",
    "\n",
    "        test_nlpd, train_nlpd, test_rmse, train_rmse\n",
    "\n",
    "        row = {\n",
    "            \"N_train\": i,\n",
    "            \"Iteration\": j,\n",
    "            \"Train_NLPD\": train_nlpd,\n",
    "            \"Train_RMSE\": train_rmse,\n",
    "            \"Test_NLPD\": test_nlpd,\n",
    "            \"Test_RMSE\": test_rmse,\n",
    "            \"TrainCode\": train_code,\n",
    "        }\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([row])])\n",
    "        df.to_csv(gen_pth / \"LMC_model2_xval.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "py,ipynb"
  },
  "kernelspec": {
   "display_name": "can_manuscript",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
