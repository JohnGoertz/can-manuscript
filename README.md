This is the data archive for the paper "Competitive Amplification Networks enable molecular pattern recognition with PCR"

The following instructions are for a Linux system. For a Windows system, you should use the Windows Subsystem for Linux 2 (WSL2). For a Mac system, you may need to install libcairo2 using different commands, but the setup after that point should be the same.

You should start in the root directory of the project.

0. Ensure you have [`mamba`](https://mamba.readthedocs.io/en/latest/installation.html) installed (or change the commands below for conda)
1. Many of the large files in the project (images and binary files such as .xlsx) are managed via [git Large File Storage (LFS)](https://git-lfs.com/). If you've downloaded this repository via `git clone`, be sure to first install git LFS then run `git lfs-install` in the cloned directory followed by `git lfs fetch --all` and possibly `git lfs pull` to ensure the files are downloaded correctly. Skipping this step could lead to errors claiming the files are corrupted when you try to open them.
2. Unzip env/candas.zip and env/nupack-4.0.1.7.zip into the env/ directory
3. Use the following commands to set up the environment.
    ```bash
    # From the root directory.
    cd env
    sudo apt update
    sudo apt install libcairo2-dev  # needed only for saving SVGs
    mamba env create -f env.yml --prefix ./can_manuscript
    conda activate can_manuscript
    ```
4. Open Jupyter Lab in a browser from the root directory for the project
    ```bash
    cd ../  # You should now be back in the can_paper/ directory
    jupyter lab
    ```

    * A browser window should open; if not, copy-paste the full hyperlink that appears into a browser.
    
5. Run each notebook
    * Open the .ipynb file in the `code/` subdirectory for each figure, and click "Run All". You may want to first remove all files from the "graphics" subdirectory to verify that they are freshly generated.
    * Keep in mind that some notebooks, in particular the ones for Fig 2, 7A, and ED1, may require 32-64GB of RAM and thus may not run to completion on a personal computer.

# Notes on figure aliases
As scientific manuscripts go through successive rounds of submission and revision, figures end up getting shuffled around and re-composed. As such, it can be difficult to keep track of which figure numbering corresponds to which version. To mitigate this confusion, this manuscript uses a system of aliases. Each figure, panel, and sub-panel is given a semi-random, unambiguous alias, e.g. "happy jaguar". A lookup table (`/figure_aliases.csv`) is then used to translate this alias to a number for the appropriate manuscript version via the `MANUSCRIPT_VERSION` variable and the formats specified in `FIG_NAME_FMT` and `DIR_NAME_FMT`. The `harmonize_figures.ipynb` notebook can be used to ensure the figure numbering for the entire repository is consistent for the specified manuscript version.

# Notes on Figure 5 "happy jaguar"
Run the _Fig8_febrile_signature_patient_data.ipynb_ notebook before _Fig8_febrile_signature_experimental.ipynb_. The _JG073 Processed patient data.csv_ and _JG073 Bayesian Logistic Regression Results.pkl_ files are generated by the _patient_data_ notebook.

Panel G was made manually.

# ParameterSets Pipeline
Many of the figures rely on aggregate data gathered from ~ two dozen experiments. This data is contained in files named along the lines of "ADVI_ParameterSet_220528.pkl". These experimental files were processed in a Snakemake pipeline. All necessary data and code is included in the `pipeline` directory. To view a dry-run of the pipeline execution, activate the environment as above, navigate to the `pipeline` directory, and run the command `snakemake -n`. Snakemake will identify which generated files are out-of-date relative to their input files, which scripts need to be executed in order to build the target file, and execute them. However, this pipeline was intended to be run in a High Performance Computing environment with extensive computational resources. It will take a very long time to complete on a personal computer, potentially exceeding the resources available (and then crashing). If needed, you can drop the `-n` flag and run simply `snakemake`, but this is not recommended.